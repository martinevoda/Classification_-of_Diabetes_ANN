{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "930a6b42-7b81-4afe-b72f-53c949de8073",
   "metadata": {},
   "source": [
    "# Diabetes Feature Engineering and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bd5a6-ff15-4ed3-b824-58455dc87ddf",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- Importing the libraries\n",
    "- Data Preprocessing\n",
    "    - Importing the dataset\n",
    "    - Handling missimg values\n",
    "    - Creating features and target\n",
    "    - Splitting the dataset into the Training set and Test set\n",
    "    - Feature Scaling\n",
    "- Building the ANN\n",
    "    - Building the Initial Model (first model)\n",
    "      - Traing the model\n",
    "      - Predicting the test result in the model\n",
    "      - Making the Confusion Matrix and evaluating the model\n",
    "      - Creating the KerasClassifier\n",
    "      - Applying K-Fold Cross Validation\n",
    "      - Applying Grid Search to find the best model and best parameters\n",
    "    - Building the Best Model (second model)\n",
    "      - Training the model with EarlyStopping\n",
    "      - Evaluation the model\n",
    "      - Predicting the test result in the model\n",
    "      - Making Confusion Matrix and evaluating the model\n",
    "    - Building the Improved Model (third model)\n",
    "      - Applying KerasClassifier to the model\n",
    "      - Applying K-Fold Cross Validation\n",
    "      - Training the model with EarlyStopping and ReduceLROnPlateau\n",
    "      - Making the Confusion Matrix and evaluating the model\n",
    "- Conclusion Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9f16f-ba46-4ba0-bc02-293bc5d6de3f",
   "metadata": {},
   "source": [
    "Introduction\n",
    "\n",
    "The dataset is structured with 9 variables for each patient:\n",
    "\n",
    "Information about dataset attributes -\n",
    "\n",
    "Pregnancies: To express the Number of pregnancies\n",
    "\n",
    "Glucose: To express the Glucose level in blood\n",
    "\n",
    "BloodPressure: To express the Blood pressure measurement\n",
    "\n",
    "SkinThickness: To express the thickness of the skin\n",
    "\n",
    "Insulin: To express the Insulin level in blood\n",
    "\n",
    "BMI: To express the Body mass index\n",
    "\n",
    "DiabetesPedigreeFunction: To express the Diabetes percentage\n",
    "\n",
    "Age: To express the age\n",
    "\n",
    "Outcome: To express the final result 1 is Yes and 0 is No\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1bc0c-256d-48bd-a008-55e2b98dc842",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbdb2638-cb27-4f61-ba0f-ede5736fd7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as snsp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034783fe-3387-42bc-bb85-c7ff3873a4fe",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8041a088-d495-4aed-9ee7-579b2150c812",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c0ad9a-286d-4887-ba3b-ba94cdc53b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba627f0-11b4-46c8-9206-3db5839828d6",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3de4231e-76e6-456c-87c1-415da36d38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SkinThickness'] = df['SkinThickness'].replace(0, np.nan)\n",
    "df['Insulin'] = df['Insulin'].replace(0, np.nan)\n",
    "df.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9f08f2d-391b-4523-83db-94f873f92f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>29.15342</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23.00000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness     Insulin   BMI  \\\n",
       "0            6      148             72       35.00000  155.548223  33.6   \n",
       "1            1       85             66       29.00000  155.548223  26.6   \n",
       "2            8      183             64       29.15342  155.548223  23.3   \n",
       "3            1       89             66       23.00000   94.000000  28.1   \n",
       "4            0      137             40       35.00000  168.000000  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602487f-5960-41ed-97a3-e6ada0d9c49d",
   "metadata": {},
   "source": [
    "### Creating features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a8ece28-c18e-46d3-8b8c-40f5b29b0fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee1dff0-b42b-41c9-bb61-6e4f94c38830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
      " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
      " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
      " ...\n",
      " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
      " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
      " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb5f375-6024-4f97-94c9-9862e94e49f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 0 1 1 0 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1\n",
      " 0 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0\n",
      " 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1\n",
      " 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 0 1\n",
      " 0 1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 1\n",
      " 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0\n",
      " 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6191695a-9c4d-4a53-b955-ac7d576f0525",
   "metadata": {},
   "source": [
    "### Splitting the dataset into Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7a96677-89be-4060-90a9-35c332b6327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8de62cd9-2081-4e20-bb13-8da97528b488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86862af2-6f11-4fbd-906a-da6141d0ef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 8), (614,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad6b883-c811-49a1-b50e-a36df2252804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((154, 8), (154,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1a3e9-c99d-4a54-aba5-616526ee8fa6",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de34c60-18b4-45f4-861f-1950982a8b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49f7b7-1589-4fd1-8ced-c696833c1a6c",
   "metadata": {},
   "source": [
    "## Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501c1de-f42a-42c6-a7a3-ac2d98f4f2e3",
   "metadata": {},
   "source": [
    "### Building the Initial Model (first model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5efd413-bf85-4d02-9be1-baa65d9d9d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init='uniform'):\n",
    "    initial_model = Sequential()\n",
    "    initial_model.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer=init, activation='relu'))\n",
    "    initial_model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    initial_model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    initial_model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return initial_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7290dc3-fcf1-4170-9624-2ad3909bdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a1052-44de-4aca-b57d-057df23a5e73",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37cbb88a-cab9-42b1-8780-771c44703cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62/62 [==============================] - 0s 521us/step - loss: 0.6862 - accuracy: 0.6498\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 457us/step - loss: 0.6416 - accuracy: 0.6547\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 470us/step - loss: 0.5514 - accuracy: 0.7394\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.4997 - accuracy: 0.7524\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4790 - accuracy: 0.7655\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4691 - accuracy: 0.7606\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.4646 - accuracy: 0.7671\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 464us/step - loss: 0.4606 - accuracy: 0.7720\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 451us/step - loss: 0.4595 - accuracy: 0.7704\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.4578 - accuracy: 0.7687\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4552 - accuracy: 0.7687\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 473us/step - loss: 0.4530 - accuracy: 0.7752\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.4513 - accuracy: 0.7720\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4497 - accuracy: 0.7769\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 465us/step - loss: 0.4490 - accuracy: 0.7785\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.4478 - accuracy: 0.7785\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.4464 - accuracy: 0.7769\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.4448 - accuracy: 0.7850\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.4443 - accuracy: 0.7834\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.4425 - accuracy: 0.7834\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4424 - accuracy: 0.7818\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 472us/step - loss: 0.4409 - accuracy: 0.7883\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.4411 - accuracy: 0.7866\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.4393 - accuracy: 0.7850\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 441us/step - loss: 0.4387 - accuracy: 0.7899\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.4378 - accuracy: 0.7850\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.4364 - accuracy: 0.7834\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.4363 - accuracy: 0.7899\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.4346 - accuracy: 0.7915\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.4338 - accuracy: 0.7948\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.4328 - accuracy: 0.7915\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 465us/step - loss: 0.4322 - accuracy: 0.7964\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.4319 - accuracy: 0.7932\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 449us/step - loss: 0.4305 - accuracy: 0.7948\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 446us/step - loss: 0.4298 - accuracy: 0.7932\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.4290 - accuracy: 0.7866\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.4290 - accuracy: 0.7948\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.4276 - accuracy: 0.7980\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 446us/step - loss: 0.4267 - accuracy: 0.8013\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 444us/step - loss: 0.4255 - accuracy: 0.7997\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 450us/step - loss: 0.4258 - accuracy: 0.8062\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 447us/step - loss: 0.4250 - accuracy: 0.7964\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.4243 - accuracy: 0.7997\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.4230 - accuracy: 0.7980\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 445us/step - loss: 0.4238 - accuracy: 0.7980\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.4222 - accuracy: 0.7997\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 452us/step - loss: 0.4217 - accuracy: 0.8029\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.4214 - accuracy: 0.8029\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 469us/step - loss: 0.4207 - accuracy: 0.7980\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 466us/step - loss: 0.4210 - accuracy: 0.7980\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 468us/step - loss: 0.4194 - accuracy: 0.8013\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 469us/step - loss: 0.4189 - accuracy: 0.8013\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 468us/step - loss: 0.4184 - accuracy: 0.8029\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 476us/step - loss: 0.4183 - accuracy: 0.8046\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 480us/step - loss: 0.4175 - accuracy: 0.8046\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.4183 - accuracy: 0.8013\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 462us/step - loss: 0.4173 - accuracy: 0.8046\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.4166 - accuracy: 0.8046\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.4164 - accuracy: 0.8029\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.4155 - accuracy: 0.8062\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.4149 - accuracy: 0.8046\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.4142 - accuracy: 0.8046\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.4146 - accuracy: 0.8078\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.4139 - accuracy: 0.8094\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 438us/step - loss: 0.4140 - accuracy: 0.8111\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 440us/step - loss: 0.4136 - accuracy: 0.8029\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.4133 - accuracy: 0.8078\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 431us/step - loss: 0.4130 - accuracy: 0.8078\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 439us/step - loss: 0.4120 - accuracy: 0.8029\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 435us/step - loss: 0.4120 - accuracy: 0.8127\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.4124 - accuracy: 0.8046\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.4116 - accuracy: 0.8094\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.4110 - accuracy: 0.8046\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.4104 - accuracy: 0.8111\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 437us/step - loss: 0.4107 - accuracy: 0.8062\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.4100 - accuracy: 0.8078\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 433us/step - loss: 0.4106 - accuracy: 0.8046\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 430us/step - loss: 0.4090 - accuracy: 0.8111\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.4086 - accuracy: 0.8078\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.4087 - accuracy: 0.8111\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 434us/step - loss: 0.4073 - accuracy: 0.8046\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 436us/step - loss: 0.4074 - accuracy: 0.8127\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 442us/step - loss: 0.4076 - accuracy: 0.8143\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 448us/step - loss: 0.4065 - accuracy: 0.8176\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 463us/step - loss: 0.4070 - accuracy: 0.8160\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 468us/step - loss: 0.4061 - accuracy: 0.8127\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 471us/step - loss: 0.4055 - accuracy: 0.8143\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 472us/step - loss: 0.4068 - accuracy: 0.8143\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 477us/step - loss: 0.4052 - accuracy: 0.8143\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 495us/step - loss: 0.4060 - accuracy: 0.8143\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.4041 - accuracy: 0.8143\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 478us/step - loss: 0.4037 - accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 474us/step - loss: 0.4032 - accuracy: 0.8160\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 467us/step - loss: 0.4029 - accuracy: 0.8160\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 513us/step - loss: 0.4025 - accuracy: 0.8160\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 483us/step - loss: 0.4024 - accuracy: 0.8208\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 495us/step - loss: 0.4035 - accuracy: 0.8192\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 689us/step - loss: 0.4025 - accuracy: 0.8176\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 521us/step - loss: 0.4016 - accuracy: 0.8225\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 504us/step - loss: 0.4006 - accuracy: 0.8208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bae0390>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model.fit(X_train, y_train, batch_size=10, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fb7f85-e794-424b-a31c-eca4557d3ff5",
   "metadata": {},
   "source": [
    "#### Predicting the test result in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b53ab1-fc63-4346-826b-658b254bcc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 629us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = initial_model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a138be2e-4ee9-4f57-b6ec-6e4198bb624a",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix and evaluting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f05a1f1f-4f43-4fe2-8865-b8ee7f98008f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[81 18]\n",
      " [20 35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7532467532467533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffddeaa7-80a2-4347-a788-68123b0f6b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        99\n",
      "           1       0.66      0.64      0.65        55\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.73      0.73      0.73       154\n",
      "weighted avg       0.75      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5de60f-a3dc-461d-8843-aa21fca5fb56",
   "metadata": {},
   "source": [
    "#### Creating the KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d62da3-cc13-4d69-a671-b3699d86614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_model = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4336828d-1068-4076-aabc-606ac70c2470",
   "metadata": {},
   "source": [
    "#### Applying K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25786dcf-0f61-417f-ae92-bdec7361c71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.31 %\n",
      "Standard Deviation: 0.34 %\n"
     ]
    }
   ],
   "source": [
    "# k-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = cross_val_score(initial_model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: {:.2f} %\".format(results.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb447738-4256-43ef-8dbf-e5ef73769ead",
   "metadata": {},
   "source": [
    "#### Applying Grid Search to find the best model and best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "345d7e54-256d-4fac-b327-5786779d2461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 11:33:06.202847: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.203818: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.223873: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.265726: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.283758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.298438: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.325062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-29 11:33:06.372314: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 928us/step\n",
      "4/4 [==============================] - 0s 897us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 887us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 935us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 867us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 948us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 484us/step\n",
      "4/4 [==============================] - 0s 919us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 885us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 761us/step\n",
      "4/4 [==============================] - 0s 724us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 717us/step\n",
      "4/4 [==============================] - 0s 641us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 644us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 970us/step\n",
      "4/4 [==============================] - 0s 799us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 897us/step\n",
      "4/4 [==============================] - 0s 977us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 489us/step\n",
      "4/4 [==============================] - 0s 907us/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 937us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 884us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 633us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 861us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 816us/step\n",
      "4/4 [==============================] - 0s 863us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 969us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 937us/step\n",
      "4/4 [==============================] - 0s 751us/step\n",
      "4/4 [==============================] - 0s 722us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 747us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 8ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 696us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 949us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 690us/step\n",
      "4/4 [==============================] - 0s 933us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 951us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 939us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 824us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 518us/step\n",
      "4/4 [==============================] - 0s 494us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 856us/step\n",
      "4/4 [==============================] - 0s 860us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 809us/step\n",
      "4/4 [==============================] - 0s 804us/step\n",
      "4/4 [==============================] - 0s 922us/step\n",
      "4/4 [==============================] - 0s 872us/step\n",
      "4/4 [==============================] - 0s 549us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 811us/step\n",
      "4/4 [==============================] - 0s 895us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 760us/step\n",
      "4/4 [==============================] - 0s 531us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 936us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 919us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 632us/step\n",
      "4/4 [==============================] - 0s 946us/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 972us/step\n",
      "4/4 [==============================] - 0s 737us/step\n",
      "4/4 [==============================] - 0s 853us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 950us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 680us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 756us/step\n",
      "4/4 [==============================] - 0s 994us/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 967us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 832us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 968us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 816us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 853us/step\n",
      "4/4 [==============================] - 0s 717us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 4ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 483us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 713us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 819us/step\n",
      "4/4 [==============================] - 0s 747us/step\n",
      "4/4 [==============================] - 0s 782us/step\n",
      "4/4 [==============================] - 0s 758us/step\n",
      "4/4 [==============================] - 0s 774us/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 864us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 801us/step\n",
      "4/4 [==============================] - 0s 986us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "4/4 [==============================] - 0s 3ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 880us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 657us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 945us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 529us/step\n",
      "4/4 [==============================] - 0s 983us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 956us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 985us/step\n",
      "4/4 [==============================] - 0s 563us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 729us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 923us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 649us/step\n",
      "4/4 [==============================] - 0s 653us/step\n",
      "4/4 [==============================] - 0s 899us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 766us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 656us/step\n",
      "4/4 [==============================] - 0s 745us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 800us/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 828us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 883us/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 938us/step\n",
      "4/4 [==============================] - 0s 814us/step\n",
      "4/4 [==============================] - 0s 599us/step\n",
      "4/4 [==============================] - 0s 419us/step\n",
      "4/4 [==============================] - 0s 392us/step\n",
      "4/4 [==============================] - 0s 345us/step\n",
      "Best Accuracy: 78.83 %\n",
      "Best Parameters:  {'batch_size': 10, 'epochs': 150, 'init': 'he_uniform', 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search with Cross-Validation\n",
    "parameters = [{'batch_size':[10,20,40], 'epochs':[50,100,150],'optimizer': ['SGD', 'RMSprop', 'Adam'], 'init' : ['uniform', 'normal', 'he_uniform']}]\n",
    "grid_search = GridSearchCV(estimator=initial_model,\n",
    "                          param_grid=parameters,\n",
    "                          scoring='accuracy',\n",
    "                          cv=kfold,\n",
    "                          n_jobs= -1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61172487-d2a4-4296-acb3-b10c8e5019f1",
   "metadata": {},
   "source": [
    "### Building the best model (second model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fa8517b-5ef9-4f22-b95c-c31b15f16147",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = create_model(optimizer=best_parameters['optimizer'], init=best_parameters['init'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0439c5-68fc-4d22-a373-f71d87ef126f",
   "metadata": {},
   "source": [
    "#### Training the model with EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc598885-bcfe-4f53-9209-5c1440b019f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8487 - accuracy: 0.6415 - val_loss: 0.8426 - val_accuracy: 0.6260\n",
      "Epoch 2/150\n",
      "50/50 [==============================] - 0s 781us/step - loss: 0.7332 - accuracy: 0.6375 - val_loss: 0.7342 - val_accuracy: 0.6179\n",
      "Epoch 3/150\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.6635 - accuracy: 0.6436 - val_loss: 0.6533 - val_accuracy: 0.6260\n",
      "Epoch 4/150\n",
      "50/50 [==============================] - 0s 796us/step - loss: 0.6058 - accuracy: 0.6375 - val_loss: 0.5970 - val_accuracy: 0.6179\n",
      "Epoch 5/150\n",
      "50/50 [==============================] - 0s 808us/step - loss: 0.5704 - accuracy: 0.6415 - val_loss: 0.5646 - val_accuracy: 0.6179\n",
      "Epoch 6/150\n",
      "50/50 [==============================] - 0s 857us/step - loss: 0.5489 - accuracy: 0.6395 - val_loss: 0.5423 - val_accuracy: 0.6179\n",
      "Epoch 7/150\n",
      "50/50 [==============================] - 0s 863us/step - loss: 0.5360 - accuracy: 0.6415 - val_loss: 0.5275 - val_accuracy: 0.6016\n",
      "Epoch 8/150\n",
      "50/50 [==============================] - 0s 852us/step - loss: 0.5270 - accuracy: 0.6497 - val_loss: 0.5195 - val_accuracy: 0.6016\n",
      "Epoch 9/150\n",
      "50/50 [==============================] - 0s 864us/step - loss: 0.5198 - accuracy: 0.6619 - val_loss: 0.5158 - val_accuracy: 0.6341\n",
      "Epoch 10/150\n",
      "50/50 [==============================] - 0s 857us/step - loss: 0.5132 - accuracy: 0.6823 - val_loss: 0.5102 - val_accuracy: 0.6423\n",
      "Epoch 11/150\n",
      "50/50 [==============================] - 0s 866us/step - loss: 0.5077 - accuracy: 0.6965 - val_loss: 0.5057 - val_accuracy: 0.6585\n",
      "Epoch 12/150\n",
      "50/50 [==============================] - 0s 834us/step - loss: 0.5034 - accuracy: 0.7149 - val_loss: 0.5020 - val_accuracy: 0.6667\n",
      "Epoch 13/150\n",
      "50/50 [==============================] - 0s 817us/step - loss: 0.4996 - accuracy: 0.7393 - val_loss: 0.4960 - val_accuracy: 0.7073\n",
      "Epoch 14/150\n",
      "50/50 [==============================] - 0s 876us/step - loss: 0.4943 - accuracy: 0.7475 - val_loss: 0.4939 - val_accuracy: 0.7073\n",
      "Epoch 15/150\n",
      "50/50 [==============================] - 0s 837us/step - loss: 0.4902 - accuracy: 0.7495 - val_loss: 0.4903 - val_accuracy: 0.7236\n",
      "Epoch 16/150\n",
      "50/50 [==============================] - 0s 826us/step - loss: 0.4869 - accuracy: 0.7556 - val_loss: 0.4892 - val_accuracy: 0.7073\n",
      "Epoch 17/150\n",
      "50/50 [==============================] - 0s 805us/step - loss: 0.4823 - accuracy: 0.7556 - val_loss: 0.4859 - val_accuracy: 0.7398\n",
      "Epoch 18/150\n",
      "50/50 [==============================] - 0s 863us/step - loss: 0.4791 - accuracy: 0.7475 - val_loss: 0.4824 - val_accuracy: 0.7480\n",
      "Epoch 19/150\n",
      "50/50 [==============================] - 0s 824us/step - loss: 0.4752 - accuracy: 0.7495 - val_loss: 0.4813 - val_accuracy: 0.7398\n",
      "Epoch 20/150\n",
      "50/50 [==============================] - 0s 814us/step - loss: 0.4717 - accuracy: 0.7434 - val_loss: 0.4798 - val_accuracy: 0.7480\n",
      "Epoch 21/150\n",
      "50/50 [==============================] - 0s 826us/step - loss: 0.4685 - accuracy: 0.7454 - val_loss: 0.4780 - val_accuracy: 0.7561\n",
      "Epoch 22/150\n",
      "50/50 [==============================] - 0s 832us/step - loss: 0.4657 - accuracy: 0.7515 - val_loss: 0.4776 - val_accuracy: 0.7480\n",
      "Epoch 23/150\n",
      "50/50 [==============================] - 0s 821us/step - loss: 0.4622 - accuracy: 0.7576 - val_loss: 0.4771 - val_accuracy: 0.7480\n",
      "Epoch 24/150\n",
      "50/50 [==============================] - 0s 831us/step - loss: 0.4593 - accuracy: 0.7637 - val_loss: 0.4754 - val_accuracy: 0.7724\n",
      "Epoch 25/150\n",
      "50/50 [==============================] - 0s 820us/step - loss: 0.4574 - accuracy: 0.7637 - val_loss: 0.4743 - val_accuracy: 0.7805\n",
      "Epoch 26/150\n",
      "50/50 [==============================] - 0s 822us/step - loss: 0.4539 - accuracy: 0.7617 - val_loss: 0.4729 - val_accuracy: 0.7967\n",
      "Epoch 27/150\n",
      "50/50 [==============================] - 0s 905us/step - loss: 0.4515 - accuracy: 0.7658 - val_loss: 0.4722 - val_accuracy: 0.8049\n",
      "Epoch 28/150\n",
      "50/50 [==============================] - 0s 814us/step - loss: 0.4501 - accuracy: 0.7617 - val_loss: 0.4721 - val_accuracy: 0.8049\n",
      "Epoch 29/150\n",
      "50/50 [==============================] - 0s 843us/step - loss: 0.4476 - accuracy: 0.7637 - val_loss: 0.4705 - val_accuracy: 0.8049\n",
      "Epoch 30/150\n",
      "50/50 [==============================] - 0s 805us/step - loss: 0.4449 - accuracy: 0.7678 - val_loss: 0.4686 - val_accuracy: 0.7967\n",
      "Epoch 31/150\n",
      "50/50 [==============================] - 0s 819us/step - loss: 0.4429 - accuracy: 0.7739 - val_loss: 0.4683 - val_accuracy: 0.8049\n",
      "Epoch 32/150\n",
      "50/50 [==============================] - 0s 825us/step - loss: 0.4413 - accuracy: 0.7800 - val_loss: 0.4671 - val_accuracy: 0.8130\n",
      "Epoch 33/150\n",
      "50/50 [==============================] - 0s 820us/step - loss: 0.4396 - accuracy: 0.7800 - val_loss: 0.4662 - val_accuracy: 0.8049\n",
      "Epoch 34/150\n",
      "50/50 [==============================] - 0s 829us/step - loss: 0.4376 - accuracy: 0.7862 - val_loss: 0.4643 - val_accuracy: 0.8049\n",
      "Epoch 35/150\n",
      "50/50 [==============================] - 0s 829us/step - loss: 0.4358 - accuracy: 0.7902 - val_loss: 0.4636 - val_accuracy: 0.8049\n",
      "Epoch 36/150\n",
      "50/50 [==============================] - 0s 822us/step - loss: 0.4353 - accuracy: 0.7923 - val_loss: 0.4636 - val_accuracy: 0.7886\n",
      "Epoch 37/150\n",
      "50/50 [==============================] - 0s 849us/step - loss: 0.4338 - accuracy: 0.7943 - val_loss: 0.4635 - val_accuracy: 0.7967\n",
      "Epoch 38/150\n",
      "50/50 [==============================] - 0s 830us/step - loss: 0.4321 - accuracy: 0.7902 - val_loss: 0.4636 - val_accuracy: 0.7886\n",
      "Epoch 39/150\n",
      "50/50 [==============================] - 0s 828us/step - loss: 0.4310 - accuracy: 0.7923 - val_loss: 0.4611 - val_accuracy: 0.7805\n",
      "Epoch 40/150\n",
      "50/50 [==============================] - 0s 807us/step - loss: 0.4286 - accuracy: 0.7943 - val_loss: 0.4615 - val_accuracy: 0.7886\n",
      "Epoch 41/150\n",
      "50/50 [==============================] - 0s 800us/step - loss: 0.4278 - accuracy: 0.7963 - val_loss: 0.4617 - val_accuracy: 0.7724\n",
      "Epoch 42/150\n",
      "50/50 [==============================] - 0s 792us/step - loss: 0.4260 - accuracy: 0.7984 - val_loss: 0.4608 - val_accuracy: 0.7805\n",
      "Epoch 43/150\n",
      "50/50 [==============================] - 0s 810us/step - loss: 0.4250 - accuracy: 0.7984 - val_loss: 0.4588 - val_accuracy: 0.7724\n",
      "Epoch 44/150\n",
      "50/50 [==============================] - 0s 809us/step - loss: 0.4233 - accuracy: 0.7984 - val_loss: 0.4612 - val_accuracy: 0.7724\n",
      "Epoch 45/150\n",
      "50/50 [==============================] - 0s 811us/step - loss: 0.4218 - accuracy: 0.8004 - val_loss: 0.4598 - val_accuracy: 0.7724\n",
      "Epoch 46/150\n",
      "50/50 [==============================] - 0s 815us/step - loss: 0.4209 - accuracy: 0.8004 - val_loss: 0.4587 - val_accuracy: 0.7724\n",
      "Epoch 47/150\n",
      "50/50 [==============================] - 0s 854us/step - loss: 0.4195 - accuracy: 0.8086 - val_loss: 0.4596 - val_accuracy: 0.7642\n",
      "Epoch 48/150\n",
      "50/50 [==============================] - 0s 844us/step - loss: 0.4195 - accuracy: 0.8065 - val_loss: 0.4605 - val_accuracy: 0.7724\n",
      "Epoch 49/150\n",
      "50/50 [==============================] - 0s 833us/step - loss: 0.4174 - accuracy: 0.8106 - val_loss: 0.4591 - val_accuracy: 0.7642\n",
      "Epoch 50/150\n",
      "50/50 [==============================] - 0s 852us/step - loss: 0.4159 - accuracy: 0.8086 - val_loss: 0.4587 - val_accuracy: 0.7642\n",
      "Epoch 51/150\n",
      "50/50 [==============================] - 0s 859us/step - loss: 0.4148 - accuracy: 0.8065 - val_loss: 0.4578 - val_accuracy: 0.7805\n",
      "Epoch 52/150\n",
      "50/50 [==============================] - 0s 847us/step - loss: 0.4135 - accuracy: 0.8086 - val_loss: 0.4561 - val_accuracy: 0.7724\n",
      "Epoch 53/150\n",
      "50/50 [==============================] - 0s 843us/step - loss: 0.4121 - accuracy: 0.8065 - val_loss: 0.4572 - val_accuracy: 0.7724\n",
      "Epoch 54/150\n",
      "50/50 [==============================] - 0s 848us/step - loss: 0.4112 - accuracy: 0.8147 - val_loss: 0.4561 - val_accuracy: 0.7724\n",
      "Epoch 55/150\n",
      "50/50 [==============================] - 0s 846us/step - loss: 0.4096 - accuracy: 0.8065 - val_loss: 0.4567 - val_accuracy: 0.7724\n",
      "Epoch 56/150\n",
      "50/50 [==============================] - 0s 843us/step - loss: 0.4094 - accuracy: 0.8126 - val_loss: 0.4549 - val_accuracy: 0.7724\n",
      "Epoch 57/150\n",
      "50/50 [==============================] - 0s 833us/step - loss: 0.4078 - accuracy: 0.8106 - val_loss: 0.4552 - val_accuracy: 0.7805\n",
      "Epoch 58/150\n",
      "50/50 [==============================] - 0s 907us/step - loss: 0.4060 - accuracy: 0.8167 - val_loss: 0.4555 - val_accuracy: 0.7724\n",
      "Epoch 59/150\n",
      "50/50 [==============================] - 0s 851us/step - loss: 0.4047 - accuracy: 0.8126 - val_loss: 0.4527 - val_accuracy: 0.7805\n",
      "Epoch 60/150\n",
      "50/50 [==============================] - 0s 839us/step - loss: 0.4043 - accuracy: 0.8126 - val_loss: 0.4525 - val_accuracy: 0.7724\n",
      "Epoch 61/150\n",
      "50/50 [==============================] - 0s 812us/step - loss: 0.4022 - accuracy: 0.8126 - val_loss: 0.4535 - val_accuracy: 0.7724\n",
      "Epoch 62/150\n",
      "50/50 [==============================] - 0s 859us/step - loss: 0.4014 - accuracy: 0.8167 - val_loss: 0.4523 - val_accuracy: 0.7724\n",
      "Epoch 63/150\n",
      "50/50 [==============================] - 0s 801us/step - loss: 0.4019 - accuracy: 0.8167 - val_loss: 0.4511 - val_accuracy: 0.7805\n",
      "Epoch 64/150\n",
      "50/50 [==============================] - 0s 814us/step - loss: 0.3999 - accuracy: 0.8167 - val_loss: 0.4507 - val_accuracy: 0.7805\n",
      "Epoch 65/150\n",
      "50/50 [==============================] - 0s 788us/step - loss: 0.3991 - accuracy: 0.8147 - val_loss: 0.4512 - val_accuracy: 0.7805\n",
      "Epoch 66/150\n",
      "50/50 [==============================] - 0s 797us/step - loss: 0.3973 - accuracy: 0.8147 - val_loss: 0.4508 - val_accuracy: 0.7724\n",
      "Epoch 67/150\n",
      "50/50 [==============================] - 0s 821us/step - loss: 0.3956 - accuracy: 0.8187 - val_loss: 0.4514 - val_accuracy: 0.7642\n",
      "Epoch 68/150\n",
      "50/50 [==============================] - 0s 809us/step - loss: 0.3952 - accuracy: 0.8187 - val_loss: 0.4505 - val_accuracy: 0.7724\n",
      "Epoch 69/150\n",
      "50/50 [==============================] - 0s 812us/step - loss: 0.3929 - accuracy: 0.8208 - val_loss: 0.4496 - val_accuracy: 0.7724\n",
      "Epoch 70/150\n",
      "50/50 [==============================] - 0s 804us/step - loss: 0.3920 - accuracy: 0.8208 - val_loss: 0.4490 - val_accuracy: 0.7724\n",
      "Epoch 71/150\n",
      "50/50 [==============================] - 0s 789us/step - loss: 0.3920 - accuracy: 0.8147 - val_loss: 0.4505 - val_accuracy: 0.7724\n",
      "Epoch 72/150\n",
      "50/50 [==============================] - 0s 787us/step - loss: 0.3899 - accuracy: 0.8228 - val_loss: 0.4504 - val_accuracy: 0.7724\n",
      "Epoch 73/150\n",
      "50/50 [==============================] - 0s 785us/step - loss: 0.3897 - accuracy: 0.8208 - val_loss: 0.4496 - val_accuracy: 0.7724\n",
      "Epoch 74/150\n",
      "50/50 [==============================] - 0s 794us/step - loss: 0.3889 - accuracy: 0.8248 - val_loss: 0.4496 - val_accuracy: 0.7724\n",
      "Epoch 75/150\n",
      "50/50 [==============================] - 0s 795us/step - loss: 0.3879 - accuracy: 0.8228 - val_loss: 0.4497 - val_accuracy: 0.7805\n",
      "Epoch 76/150\n",
      "50/50 [==============================] - 0s 782us/step - loss: 0.3859 - accuracy: 0.8269 - val_loss: 0.4506 - val_accuracy: 0.7805\n",
      "Epoch 77/150\n",
      "50/50 [==============================] - 0s 783us/step - loss: 0.3844 - accuracy: 0.8208 - val_loss: 0.4495 - val_accuracy: 0.7724\n",
      "Epoch 78/150\n",
      "50/50 [==============================] - 0s 794us/step - loss: 0.3828 - accuracy: 0.8228 - val_loss: 0.4497 - val_accuracy: 0.7642\n",
      "Epoch 79/150\n",
      "50/50 [==============================] - 0s 823us/step - loss: 0.3818 - accuracy: 0.8228 - val_loss: 0.4481 - val_accuracy: 0.7724\n",
      "Epoch 80/150\n",
      "50/50 [==============================] - 0s 786us/step - loss: 0.3809 - accuracy: 0.8228 - val_loss: 0.4491 - val_accuracy: 0.7724\n",
      "Epoch 81/150\n",
      "50/50 [==============================] - 0s 790us/step - loss: 0.3803 - accuracy: 0.8208 - val_loss: 0.4489 - val_accuracy: 0.7724\n",
      "Epoch 82/150\n",
      "50/50 [==============================] - 0s 793us/step - loss: 0.3788 - accuracy: 0.8289 - val_loss: 0.4480 - val_accuracy: 0.7805\n",
      "Epoch 83/150\n",
      "50/50 [==============================] - 0s 797us/step - loss: 0.3792 - accuracy: 0.8289 - val_loss: 0.4483 - val_accuracy: 0.7642\n",
      "Epoch 84/150\n",
      "50/50 [==============================] - 0s 821us/step - loss: 0.3784 - accuracy: 0.8289 - val_loss: 0.4489 - val_accuracy: 0.7724\n",
      "Epoch 85/150\n",
      "50/50 [==============================] - 0s 851us/step - loss: 0.3765 - accuracy: 0.8228 - val_loss: 0.4478 - val_accuracy: 0.7724\n",
      "Epoch 86/150\n",
      "50/50 [==============================] - 0s 864us/step - loss: 0.3766 - accuracy: 0.8228 - val_loss: 0.4481 - val_accuracy: 0.7642\n",
      "Epoch 87/150\n",
      "50/50 [==============================] - 0s 842us/step - loss: 0.3764 - accuracy: 0.8310 - val_loss: 0.4491 - val_accuracy: 0.7724\n",
      "Epoch 88/150\n",
      "50/50 [==============================] - 0s 834us/step - loss: 0.3747 - accuracy: 0.8248 - val_loss: 0.4484 - val_accuracy: 0.7642\n",
      "Epoch 89/150\n",
      "50/50 [==============================] - 0s 831us/step - loss: 0.3736 - accuracy: 0.8269 - val_loss: 0.4471 - val_accuracy: 0.7642\n",
      "Epoch 90/150\n",
      "50/50 [==============================] - 0s 812us/step - loss: 0.3733 - accuracy: 0.8330 - val_loss: 0.4477 - val_accuracy: 0.7642\n",
      "Epoch 91/150\n",
      "50/50 [==============================] - 0s 795us/step - loss: 0.3723 - accuracy: 0.8269 - val_loss: 0.4481 - val_accuracy: 0.7642\n",
      "Epoch 92/150\n",
      "50/50 [==============================] - 0s 802us/step - loss: 0.3712 - accuracy: 0.8269 - val_loss: 0.4471 - val_accuracy: 0.7805\n",
      "Epoch 93/150\n",
      "50/50 [==============================] - 0s 787us/step - loss: 0.3710 - accuracy: 0.8269 - val_loss: 0.4487 - val_accuracy: 0.7642\n",
      "Epoch 94/150\n",
      "50/50 [==============================] - 0s 788us/step - loss: 0.3696 - accuracy: 0.8310 - val_loss: 0.4493 - val_accuracy: 0.7724\n",
      "Epoch 95/150\n",
      "50/50 [==============================] - 0s 804us/step - loss: 0.3683 - accuracy: 0.8310 - val_loss: 0.4488 - val_accuracy: 0.7724\n",
      "Epoch 96/150\n",
      "50/50 [==============================] - 0s 833us/step - loss: 0.3686 - accuracy: 0.8310 - val_loss: 0.4501 - val_accuracy: 0.7642\n",
      "Epoch 97/150\n",
      "50/50 [==============================] - 0s 810us/step - loss: 0.3665 - accuracy: 0.8330 - val_loss: 0.4511 - val_accuracy: 0.7642\n",
      "Epoch 98/150\n",
      "50/50 [==============================] - 0s 784us/step - loss: 0.3664 - accuracy: 0.8330 - val_loss: 0.4507 - val_accuracy: 0.7642\n",
      "Epoch 99/150\n",
      "50/50 [==============================] - 0s 778us/step - loss: 0.3656 - accuracy: 0.8350 - val_loss: 0.4516 - val_accuracy: 0.7724\n",
      "Epoch 100/150\n",
      "50/50 [==============================] - 0s 787us/step - loss: 0.3649 - accuracy: 0.8330 - val_loss: 0.4525 - val_accuracy: 0.7724\n",
      "Epoch 101/150\n",
      "50/50 [==============================] - 0s 780us/step - loss: 0.3658 - accuracy: 0.8310 - val_loss: 0.4544 - val_accuracy: 0.7805\n",
      "Epoch 102/150\n",
      "50/50 [==============================] - 0s 849us/step - loss: 0.3637 - accuracy: 0.8371 - val_loss: 0.4541 - val_accuracy: 0.7805\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = best_model.fit(X_train, y_train, validation_split=0.2, epochs=best_parameters['epochs'], batch_size=best_parameters['batch_size'], callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f48a70-6168-4308-a3eb-72382a92f98e",
   "metadata": {},
   "source": [
    "#### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1d89b1a-96f3-4f7c-bc0d-6034873135b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.7208\n",
      "Final model - Loss: 0.5649195909500122, Accuracy: 0.7207792401313782\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Final model - Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b8459-070c-4445-9b66-54ce0b70be3d",
   "metadata": {},
   "source": [
    "#### Predicting the test result in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8f5a6e5-25ed-4d61-afdd-4a500d62fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 623us/step\n"
     ]
    }
   ],
   "source": [
    "y_best_pred = (best_model.predict(X_test) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231bd14-da8a-47db-9b65-1678b14f8541",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dec02de6-4c5c-4dc3-a2e3-835f4eda1453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 23]\n",
      " [20 35]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7207792207792207"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_best = confusion_matrix(y_test, y_best_pred)\n",
    "print(cm_best)\n",
    "accuracy_score(y_test, y_best_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c32fae3-64e4-4de2-ad9f-e1c53b76ba1d",
   "metadata": {},
   "source": [
    "### Building the Improved Model (third model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d48e32fb-b59b-450a-8817-bd5c816e162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_improved_model(optimizer='adam', init='uniform'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=X_train.shape[1], kernel_initializer=init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, kernel_initializer=init, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, kernel_initializer=init, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1618c-1679-40cc-b211-2872c80c0373",
   "metadata": {},
   "source": [
    "#### Applying KerasClassifier to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72299454-d306-4f63-aa6a-745e6bd29248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the Keras model\n",
    "keras_clf = KerasClassifier(build_fn=create_improved_model, \n",
    "                            optimizer=best_parameters['optimizer'], \n",
    "                            init=best_parameters['init'], \n",
    "                            epochs=best_parameters['epochs'], \n",
    "                            batch_size=best_parameters['batch_size'], \n",
    "                            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191472e-b0e8-4fc1-b664-51cc0d266c3e",
   "metadata": {},
   "source": [
    "#### Applying K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1888a32a-fc42-435a-afd6-3441c85bf9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 598us/step\n",
      "4/4 [==============================] - 0s 632us/step\n",
      "4/4 [==============================] - 0s 692us/step\n",
      "4/4 [==============================] - 0s 615us/step\n",
      "4/4 [==============================] - 0s 630us/step\n",
      "CV Accuracy: 75.40 %\n",
      "CV Standard Deviation: 2.24 %\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = cross_val_score(keras_clf, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "print(\"CV Accuracy: {:.2f} %\".format(cv_results.mean()*100))\n",
    "print(\"CV Standard Deviation: {:.2f} %\".format(cv_results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d8cf7-f6a5-4fe5-91bf-4e6dcd3b40b8",
   "metadata": {},
   "source": [
    "#### Training the Improved Model with EarlyStopping and ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a32b771-3d12-4781-a3cf-fc1ee352105f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4978 - accuracy: 0.7597 - val_loss: 0.4711 - val_accuracy: 0.7480 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "50/50 [==============================] - 0s 998us/step - loss: 0.4991 - accuracy: 0.7475 - val_loss: 0.4720 - val_accuracy: 0.7480 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "50/50 [==============================] - 0s 999us/step - loss: 0.5131 - accuracy: 0.7699 - val_loss: 0.4707 - val_accuracy: 0.7398 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.7149 - val_loss: 0.4725 - val_accuracy: 0.7398 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7556 - val_loss: 0.4702 - val_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "50/50 [==============================] - 0s 982us/step - loss: 0.5147 - accuracy: 0.7515 - val_loss: 0.4704 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "50/50 [==============================] - 0s 986us/step - loss: 0.5348 - accuracy: 0.7393 - val_loss: 0.4753 - val_accuracy: 0.7480 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "50/50 [==============================] - 0s 954us/step - loss: 0.5208 - accuracy: 0.7495 - val_loss: 0.4749 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7434 - val_loss: 0.4726 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "50/50 [==============================] - 0s 998us/step - loss: 0.5104 - accuracy: 0.7251 - val_loss: 0.4736 - val_accuracy: 0.7480 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "50/50 [==============================] - 0s 997us/step - loss: 0.5346 - accuracy: 0.7576 - val_loss: 0.4711 - val_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "50/50 [==============================] - 0s 960us/step - loss: 0.5125 - accuracy: 0.7495 - val_loss: 0.4717 - val_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "50/50 [==============================] - 0s 991us/step - loss: 0.5255 - accuracy: 0.7332 - val_loss: 0.4716 - val_accuracy: 0.7561 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.7332 - val_loss: 0.4740 - val_accuracy: 0.7642 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5172 - accuracy: 0.7373 - val_loss: 0.4735 - val_accuracy: 0.7561 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "history = best_model_improved.fit(X_train, y_train, validation_split=0.2, epochs=best_parameters['epochs'], \n",
    "                         batch_size=best_parameters['batch_size'], callbacks=[early_stopping, reduce_lr], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e8efd-bf70-4251-bbb0-3a3278f7563e",
   "metadata": {},
   "source": [
    "### Making the Confusion Matrix and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6bcd49d-4614-4131-8bac-642b032bc9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 799us/step\n",
      "[[85 14]\n",
      " [21 34]]\n",
      "0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_best_pred = (best_model_improved.predict(X_test) > 0.5)\n",
    "cm_best = confusion_matrix(y_test, y_best_pred)\n",
    "print(cm_best)\n",
    "print(accuracy_score(y_test, y_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045adf86-f8fd-439d-b83c-d046cb8203c2",
   "metadata": {},
   "source": [
    "## Conclusion Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f02a46-0b5e-4a96-984c-029930cc13c4",
   "metadata": {},
   "source": [
    "The code provided implements several machine learning models to predict diabetes based on various patient metrics. Here's a step-by-step analysis of each model and the results obtained:\n",
    "\n",
    "Data Preprocessing\n",
    "\n",
    "The dataset is loaded, and missing values are handled by replacing zeros with the mean value in the 'SkinThickness' and 'Insulin' columns. This step ensures that the dataset is complete and can be processed without errors due to missing values. The dataset is then split into features (X) and target (y) variables, where X contains all columns except the target variable (diabetes outcome), and y contains the target variable.\n",
    "The data is then split into training and testing sets using an 80-20 split. This allows the model to be trained on a portion of the data and tested on another to evaluate its performance. The data is also normalized using StandardScaler to standardize the features, which is a common practice in machine learning to improve model performance.\n",
    "\n",
    "Building ANN\n",
    "\n",
    "A simple neural network model is created using Keras. The model consists of three layers: an input layer, one hidden layer, and an output layer. The model is compiled with the 'adam' optimizer and 'binary_crossentropy' loss function, which are suitable for binary classification problems. The model is then trained on the training data for 100 epochs. After training, the model's performance is evaluated on the test data, resulting in an accuracy of 75.32%. The confusion matrix and classification report indicate that the model has a higher precision for predicting non-diabetic patients (class 0) than diabetic patients (class 1).\n",
    "Next, a KerasClassifier is created to enable the use of scikit-learn's cross-validation and grid search capabilities. The model undergoes k-fold cross-validation with 5 splits to ensure it generalizes well to unseen data. The initial cross-validation accuracy is 65.31%, with a standard deviation of 0.34%, suggesting that the model's performance is relatively stable but can be improved\n",
    "A grid search is performed to find the best hyperparameters for the model, including batch size, epochs, optimizer, and weight initialization method. The best parameters found are batch size of 10, 150 epochs, 'he_uniform' initialization, and the 'Adam' optimizer. Using these parameters, the model is retrained with early stopping to prevent overfitting. The final model achieves an accuracy of 72.08% on the test set.\n",
    "The first model's higher accuracy might be due to its simplicity and effective learning dynamics with the 'adam' optimizer. The second model, despite having optimized parameters, faced a slight drop in accuracy possibly due to overfitting, increased model complexity, data split variance, and noise in hyperparameter tuning. This highlights the importance of cross-validation and careful interpretation of hyperparameter optimization results.\n",
    "To further improve the model, an enhanced neural network is created with additional layers for batch normalization and dropout. These techniques help improve model stability and reduce overfitting. The improved model is also wrapped in a KerasClassifier and evaluated using cross-validation. This model achieves a cross-validation accuracy of 75.40%, with a standard deviation of 2.24%, indicating more consistent performance across different splits of the data.\n",
    "Finally, early stopping and a learning rate scheduler are implemented to further optimize the training process. The early stopping callback monitors the validation loss and stops training if it doesn't improve for 10 consecutive epochs, while the learning rate scheduler reduces the learning rate if the validation loss plateaus. The improved model achieves an accuracy of 77.27% on the test set, with a confusion matrix showing better performance in predicting both classes compared to the initial models.\n",
    "\n",
    "In conclusion, the process involves iteratively refining the model by handling missing values, normalizing the data, experimenting with different neural network architectures, and using techniques like grid search, cross-validation, early stopping, and learning rate scheduling. The final model with batch normalization, dropout, and optimized hyperparameters shows significant improvement in accuracy and consistency, demonstrating the importance of systematic model tuning and evaluation in machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a5e5f3-f44e-44dc-99f1-5790668fcae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
